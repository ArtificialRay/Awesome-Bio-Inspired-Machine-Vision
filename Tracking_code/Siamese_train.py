import os
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader


# === Siamese ç›¸ä¼¼åº¦ç½‘ç»œï¼ˆè¾“å‡º 0~1ï¼‰ ===
class SiameseNet(nn.Module):
    def __init__(self, input_dim=128):
        
        )
        self.output_layer = nn.Sequential(
            
        )

    def forward(self, x1, x2):
        out1 = 
        out2 = 
        diff =
        sim = 
        return sim


class PairDataset(Dataset):
    def __init__(self, pairs, labels):
       

    def __len__(self):
        return len(self.y)

    def __getitem__(self, idx):
        return self.x1[idx], self.x2[idx], self.y[idx]


# === åŠ è½½æ£€æµ‹æ•°æ® ===
def load_detections(detection_array, vis_threshold=0.0):
    id_to_feats = {}
    

def build_pairs(id_to_feats):
    
    return np.array(pairs), np.array(labels)


def main(vis_threshold=0.3, epochs=50):
    

        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss, correct, total = 0.0, 0, 0
        with torch.no_grad():
            for x1, x2, y in val_loader:
                x1, x2, y = x1.to(device), x2.to(device), y.to(device)
                outputs = model(x1, x2)
                val_loss += criterion(outputs, y).item()
                preds = (outputs > 0.5).float()
                correct += (preds == y).sum().item()
                total += y.size(0)

        val_acc = correct / total
        print(f"[{epoch:02d}] Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2%}")

        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save(model.state_dict(), "similarity_model/best_model.pth")
            print("ğŸ“Œ Best model saved!")

    print("âœ… å®Œæˆè®­ç»ƒï¼Œæ¨¡å‹å·²ä¿å­˜")


if __name__ == '__main__':
    main(0.001, 80)
